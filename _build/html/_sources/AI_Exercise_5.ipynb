{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Python Knowledge Repetition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning packages\n",
    "\n",
    "<img src=\"img/ML.png\" width=\"450\" style=\"display: block; margin: 0 auto;\" />\n",
    "\n",
    "\n",
    "<img src=\"img/ML2.png\" width=\"700\" style=\"display: block; margin: 0 auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "\n",
    "#### Pandas\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">Pandas offers efficient and flexible data structures that enable users to work with data in an easy and intuitive manner. This high-level framework, built on Python, is one of the most widely used tools for data analysis and manipulation. Its core objects include Series and DataFrame, and it supports a variety of useful operations such as label-based slicing, merging and joining, hierarchical indexing, as well as reshaping and pivoting of data.</span> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame containing employee data, filters it to display employees with a salary greater than 60,000, and calculates the average age of all employees in the DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [24, 27, 22, 32, 29],\n",
    "    'Salary': [50000, 60000, 45000, 70000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Filter DataFrame for employees with a salary greater than 60000\n",
    "high_salary = df[df['Salary'] > 60000]\n",
    "print(\"\\nEmployees with salary greater than 60000:\")\n",
    "print(high_salary)\n",
    "\n",
    "# Calculate and display the average age\n",
    "average_age = df['Age'].mean()\n",
    "print(\"\\nAverage Age:\", average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with employee data, groups the data by department, and calculates the average salary for each department, displaying both the original DataFrame and the computed averages\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple DataFrame\n",
    "data = {\n",
    "    'Department': ['HR', 'IT', 'IT', 'HR', 'Finance'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Salary': [50000, 60000, 45000, 70000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by Department and calculate the average salary\n",
    "average_salary_by_department = df.groupby('Department')['Salary'].mean().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nAverage Salary by Department:\")\n",
    "print(average_salary_by_department)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "<span style=\"color: orange; font-size: 18px;\">NumPy offers robust N-dimensional array objects along with a variety of advanced mathematical functions to manipulate these arrays. NumPy arrays are particularly beneficial when handling large datasets, as they provide a reduced memory footprint and faster execution times compared to standard Python lists.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the slope and intercept of a simple linear regression line using synthetic data, and then predicts target values for new feature inputs\n",
    "import numpy as np\n",
    "\n",
    "# Generate simple synthetic data\n",
    "X = np.array([1, 2, 3, 4, 5])  # Feature values\n",
    "y = np.array([2, 4, 5, 4, 5])  # Target values\n",
    "\n",
    "# Calculate the slope (m) and intercept (b) for the line y = mx + b\n",
    "# Using the formula for linear regression coefficients\n",
    "X_mean = np.mean(X)\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "# Calculate the slope (m)\n",
    "numerator = np.sum((X - X_mean) * (y - y_mean))\n",
    "denominator = np.sum((X - X_mean) ** 2)\n",
    "m = numerator / denominator\n",
    "\n",
    "# Calculate the intercept (b)\n",
    "b = y_mean - m * X_mean\n",
    "\n",
    "# Predicting new values\n",
    "X_new = np.array([6, 7])  # New feature values\n",
    "y_predict = m * X_new + b  # Predictions\n",
    "\n",
    "# Print the results\n",
    "print(\"Slope (m):\", m)\n",
    "print(\"Intercept (b):\", b)\n",
    "print(\"Predictions for X_new:\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a linear regression model using gradient descent to estimate weights based on a dataset with multiple features, and it predicts target values based on the learned weights\n",
    "import numpy as np\n",
    "\n",
    "# Sample data: Features (X) and Target (y)\n",
    "# Here, we have 3 features and 5 samples\n",
    "X = np.array([[1, 2, 3],\n",
    "              [2, 3, 4],\n",
    "              [3, 5, 6],\n",
    "              [4, 5, 7],\n",
    "              [5, 6, 8]])  # 5 samples, 3 features\n",
    "\n",
    "y = np.array([1, 2, 3, 4, 5])  # Target variable\n",
    "\n",
    "# Add bias term (intercept) to the features\n",
    "X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add x0 = 1\n",
    "\n",
    "# Gradient Descent Parameters\n",
    "learning_rate = 0.01\n",
    "n_iterations = 1000\n",
    "m = len(y)  # Number of samples\n",
    "theta = np.random.randn(X_b.shape[1])  # Random initialization of weights\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = (1/m) * X_b.T.dot(X_b.dot(theta) - y)  # Calculate gradients\n",
    "    theta -= learning_rate * gradients  # Update weights\n",
    "\n",
    "# Predictions\n",
    "y_pred = X_b.dot(theta)\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated Weights (Theta):\", theta)\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "#### Matplotlib\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">Matplotlib is the leading library for data visualization in Python. It is constructed on top of NumPy arrays and integrates seamlessly with the SciPy ecosystem. This library enables users to create a variety of visual representations of their datasets, including figures and plots. One of its notable advantages is its compatibility with various operating systems and graphical output formats. Additionally, many modern libraries, such as Seaborn and HoloViews, leverage the capabilities of Matplotlib to enhance their visualization features.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating training and validation loss data over 20 epochs and visualizes the results using Matplotlib, allowing for a comparison of how each loss metric evolves throughout the training process\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Simulated training and validation loss data\n",
    "epochs = np.arange(1, 21)  # 20 epochs\n",
    "train_loss = np.exp(-0.1 * epochs) + np.random.normal(0, 0.01, len(epochs))  # Simulated train loss\n",
    "val_loss = np.exp(-0.1 * epochs) + np.random.normal(0, 0.02, len(epochs))  # Simulated validation loss\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss', color='blue', marker='o')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss', color='orange', marker='o')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs)  # Set x-ticks to be the epochs\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)  # Set limits for the y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating synthetic data, fits a linear regression model to it using the Normal Equation, and visualizes the data points along with the fitted regression line using Matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = 2 * np.random.rand(100, 1)  # 100 random points in range [0, 2]\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)  # Linear relation with some noise\n",
    "\n",
    "# Fit a linear regression model using the Normal Equation\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # Add x0 = 1 for bias\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)  # Calculate optimal theta\n",
    "\n",
    "# Predict using the linear model\n",
    "y_pred = X_b.dot(theta_best)\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='blue', label='Data points')  # Plot the original data points\n",
    "plt.plot(X, y_pred, color='red', label='Linear regression line')  # Plot the regression line\n",
    "plt.title('Linear Regression with Synthetic Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific Computing\n",
    "\n",
    "#### SciPy\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">This library is a compilation of mathematical algorithms and utility functions that are built upon the NumPy library, utilizing its array structures. It includes a variety of advanced modules designed for tasks such as linear algebra, optimization, interpolation, fast Fourier transforms (FFT), image processing, and ordinary differential equation (ODE) solvers, among others.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciPy to perform linear regression on a synthetic dataset and visualize the results using Matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = 2 * np.random.rand(100)  # 100 random points in range [0, 2]\n",
    "y = 4 + 3 * X + np.random.randn(100)  # Linear relation with some noise\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'X': X, 'y': y})\n",
    "\n",
    "# Perform linear regression using scipy stats\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['X'], df['y'])\n",
    "\n",
    "# Predict using the linear model\n",
    "df['y_pred'] = intercept + slope * df['X']\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['X'], df['y'], color='blue', label='Data points')  # Original data points\n",
    "plt.plot(df['X'], df['y_pred'], color='red', label='Fitted line')  # Regression line\n",
    "plt.title('Linear Regression with SciPy')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print slope and intercept\n",
    "print(f\"Slope: {slope}, Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization functions to minimize a simple objective function and visualize the result\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define an objective function\n",
    "def objective_function(x):\n",
    "    return (x - 2) ** 2 + 1  # A simple quadratic function\n",
    "\n",
    "# Initial guess\n",
    "x0 = 0\n",
    "\n",
    "# Perform optimization using SciPy\n",
    "result = minimize(objective_function, x0)\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_values = np.linspace(-1, 5, 100)\n",
    "y_values = objective_function(x_values)\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, y_values, label='Objective Function', color='blue')  # Plot the objective function\n",
    "plt.scatter(result.x, result.fun, color='red', label='Optimal Point')  # Mark the optimal point\n",
    "plt.title('Optimization Example with SciPy')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='black', lw=0.5)  # Add x-axis\n",
    "plt.axvline(0, color='black', lw=0.5)  # Add y-axis\n",
    "plt.show()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Optimal x: {result.x[0]}, Function value: {result.fun}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "\n",
    "#### Scikit-learn\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">Scikit-learn is a widely-used library in Python for machine learning, offering an extensive range of both supervised and unsupervised learning models. It features a user-friendly and efficient API with a consistent syntax, making it simple to switch between various algorithms and models. Additionally, Scikit-learn provides numerous auxiliary functions for tasks such as data preprocessing, resampling, evaluation of model performance, and tuning of hyperparameters.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris dataset to perform classification using a decision tree and visualize the results\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # All features\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "tree.plot_tree(model, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA) to reduce the dimensionality of the Iris dataset for visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # All features\n",
    "y = iris.target\n",
    "\n",
    "# Apply PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame for the reduced data\n",
    "df = pd.DataFrame(X_reduced, columns=['PC1', 'PC2'])\n",
    "df['target'] = y\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['PC1'], df['PC2'], c=df['target'], cmap='viridis', edgecolors='k', marker='o')\n",
    "plt.title('PCA of Iris Dataset')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(ticks=[0, 1, 2], label='Iris Species')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">TensorFlow, created by Google, is one of the leading libraries used for large-scale machine learning and deep learning applications. It functions as a framework for numerical computations involving data flow graphs, where the nodes represent various mathematical operations, and the edges signify tensors, which are essentially multidimensional arrays. TensorFlow offers both high-level APIs, like tf.Keras, for ease of use, as well as low-level APIs for those requiring more detailed control over their models. Additionally, it supports training on distributed servers and enables deployment on a wide range of platforms, including desktops, servers, embedded IoT devices, and mobile devices.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple neural network using TensorFlow to classify the Iris dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "X_test = X_test.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Reshape the data to include channel dimension\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize some test images and their predicted classes\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Display some test images and predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Predicted: {np.argmax(predictions[i])}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">Keras is a high-level API for neural networks that can operate on top of frameworks like TensorFlow. It was designed to facilitate quick experimentation and prototyping of machine learning models. Keras supports a variety of deep learning architectures, including convolutional and recurrent neural networks. Developed by François Chollet, Keras was created with several key principles in mind: modularity, ease of use, simple extensibility, and compatibility with Python.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple neural network to fit a polynomial function using Keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.linspace(-1, 1, 100)  # 100 points from -1 to 1\n",
    "y = X ** 2 + np.random.normal(0, 0.1, X.shape)  # y = x^2 with noise\n",
    "\n",
    "# Reshape the data\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Create a simple neural network model for regression\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(10, activation='relu', input_shape=(1,)),  # Input layer\n",
    "    layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X, y, label='Data', color='blue')\n",
    "plt.plot(X, y_pred, label='Model Prediction', color='red')\n",
    "plt.title('Polynomial Regression (y = x^2)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple neural network to predict future values in a sine wave using Keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Generate sine wave data\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 50, 1000)\n",
    "y = np.sin(X) + np.random.normal(0, 0.1, X.shape)  # Sine wave with noise\n",
    "\n",
    "# Prepare the data for training\n",
    "X_train = X[:-100].reshape(-1, 1)  # Use all but the last 100 points for training\n",
    "y_train = y[:-100].reshape(-1, 1)\n",
    "X_test = X[-100:].reshape(-1, 1)  # Last 100 points for testing\n",
    "y_test = y[-100:].reshape(-1, 1)\n",
    "\n",
    "# Create a simple neural network model for regression\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(10, activation='relu', input_shape=(1,)),  # Input layer\n",
    "    layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(X_test, y_test, label='True', color='blue')\n",
    "plt.plot(X_test, y_pred, label='Prediction', color='red')\n",
    "plt.title('Sine Wave Prediction')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">PyTorch is a machine learning library that is built on the Torch framework, which utilizes the Lua programming language. The primary features of PyTorch include tensor computations and automatic differentiation, making it ideal for constructing and training neural networks. In recent years, PyTorch has gained significant popularity, partly due to its capability to define computational graphs dynamically. This flexibility contrasts with most other deep learning libraries that necessitate the definition of the computational graph before executing the model.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear model to a small dataset using PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1) * 10  # 100 random points from 0 to 10\n",
    "y = 2 * X + 1 + np.random.randn(100, 1)  # y = 2x + 1 + noise\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "# Define a simple linear model\n",
    "model = nn.Linear(1, 1)  # Input and output are both one-dimensional\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):  # 100 epochs\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    y_pred = model(X_tensor)  # Forward pass\n",
    "    loss = criterion(y_pred, y_tensor)  # Calculate loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X, y, color='blue', label='Data')\n",
    "plt.plot(X, model(X_tensor).detach().numpy(), color='red', label='Prediction')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a neural network to predict values of a sine wave\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sine wave data\n",
    "X = np.linspace(0, 10, 100)  # 100 points from 0 to 10\n",
    "y = np.sin(X)  # Sine wave\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X).view(-1, 1)  # Reshape for PyTorch\n",
    "y_tensor = torch.FloatTensor(y).view(-1, 1)  # Reshape for PyTorch\n",
    "\n",
    "# Define a simple neural network model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 10),  # Input layer to hidden layer\n",
    "    nn.ReLU(),         # Activation function\n",
    "    nn.Linear(10, 1)   # Hidden layer to output layer\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):  # 100 epochs\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    y_pred = model(X_tensor)  # Forward pass\n",
    "    loss = criterion(y_pred, y_tensor)  # Calculate loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(X, y, label='True Sine Wave', color='blue')\n",
    "plt.plot(X, model(X_tensor).detach().numpy(), label='Model Prediction', color='red')\n",
    "plt.title('Sine Wave Prediction')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('sin(X)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision\n",
    "\n",
    "#### OpenCV\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">OpenCV is a  library designed for computer vision and machine learning applications. It aims to deliver a unified platform for various computer vision tasks. The library boasts over 2,500 algorithms that facilitate face detection and recognition, object identification, human action classification in videos, tracking of moving objects, and the extraction of 3D object models, among other functionalities. OpenCV is utilized in numerous sectors, including industry, academia, and government organizations. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading an image, resize it to a smaller size, and display the resized image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image from file\n",
    "image = cv2.imread(\"img/roulette.jpg\")  \n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "else:\n",
    "    # Resize the image to half its original size using INTER_AREA for faster scaling\n",
    "    resized_image = cv2.resize(image, (image.shape[1] // 2, image.shape[0] // 2), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Save the resized image to verify the result\n",
    "    cv2.imwrite('resized_image.jpg', resized_image)\n",
    "    print(\"Resized image saved as 'resized_image.jpg'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a color image to grayscale and display the grayscale image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image from file (this will still take time depending on image size)\n",
    "image = cv2.imread(\"img/interp.png\")  \n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "else:\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Save the grayscale image to verify the result\n",
    "    cv2.imwrite('gray_image.png', gray_image)\n",
    "    print(\"Grayscale image saved as 'gray_image.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-image\n",
    "\n",
    "<span style=\"color: orange; font-size: 18px;\">scikit-image is a Python library for to image processing. It is using natively NumPy arrays as image objects. Scikit-image includes a wide range of algorithms – for segmentation, geometric transformations, color space manipulation, analysis, filtering, morphology, feature detection, and more. It is designed to be compatible with both NumPy and SciPy libraries. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a Gaussian filter to an image to blur it, which can help in noise reduction\n",
    "from skimage import io, filters\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load an image from file using OpenCV\n",
    "image = cv2.imread(\"img/Student.png\")  # Replace with your image path\n",
    "\n",
    "# Convert the image from BGR (OpenCV format) to RGB\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Apply Gaussian filter to the image\n",
    "blurred_image = filters.gaussian(image_rgb, sigma=1)  # No need for 'multichannel' parameter\n",
    "\n",
    "# Display the original and blurred images using Matplotlib\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(image_rgb)  # Display the RGB image\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(blurred_image)  # Display the blurred image\n",
    "ax[1].set_title('Blurred Image (Gaussian Filter)')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing edge detection on an image using the Canny edge detection algorithm, and then display both the original grayscale image and the detected edges side by side\n",
    "from skimage import io, feature, color  # Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # Make sure to import OpenCV if you're using cv2\n",
    "\n",
    "# Load an image from file using OpenCV\n",
    "image = cv2.imread(\"img/roulette.jpg\") \n",
    "\n",
    "# Convert the image to grayscale (Canny expects a grayscale image)\n",
    "gray_image = color.rgb2gray(image)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = feature.canny(gray_image, sigma=1)  # sigma controls the level of Gaussian smoothing before edge detection\n",
    "\n",
    "# Display the original image and the edges using Matplotlib\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(gray_image, cmap='gray')\n",
    "ax[0].set_title('Grayscale Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(edges, cmap='gray')\n",
    "ax[1].set_title('Canny Edges')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
