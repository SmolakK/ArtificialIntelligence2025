{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d584f822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc949f0ee87496388e7b60726cd926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Degree', max=20, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10  # Random data points between 0 and 10\n",
    "y = 2 * X**2 - 3 * X + np.random.randn(100, 1) * 22  # Quadratic relation with noise\n",
    "\n",
    "# Function to plot the data and regression fit\n",
    "def plot_regression_fit(degree=1):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create polynomial features based on selected degree\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X, y)\n",
    "    X_fit = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    y_fit = model.predict(X_fit)\n",
    "\n",
    "    # Plot data and regression fit\n",
    "    plt.scatter(X, y, color=\"blue\", label=\"Data\", alpha=0.6)\n",
    "    plt.plot(X_fit, y_fit, color=\"red\", label=f\"Degree {degree} fit\")\n",
    "    \n",
    "    plt.title(f\"Polynomial Regression with Degree {degree}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widgets\n",
    "interact(plot_regression_fit, \n",
    "         degree=IntSlider(min=1, max=20, step=1, value=1, description='Degree'));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfdd5940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac79c2b284dc40caaed6109b4a0d5634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Iteration', max=999), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "# Generate synthetic dataset\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + 3*X**3 - np.random.randn(100, 1)  # Linear relation with some noise\n",
    "\n",
    "# Prepare the data for gradient descent\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # Add x0 = 1 to each instance (for bias term)\n",
    "m = len(X_b)\n",
    "\n",
    "# Function to perform gradient descent\n",
    "def gradient_descent(theta, X_b, y, learning_rate=0.1, n_iterations=1000):\n",
    "    history = []\n",
    "    for iteration in range(n_iterations):\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - learning_rate * gradients\n",
    "        history.append(theta.copy())  # Store each step of theta\n",
    "    return history\n",
    "\n",
    "# Initialize theta (random initial guess)\n",
    "initial_theta = np.random.randn(2, 1)\n",
    "\n",
    "# Perform gradient descent\n",
    "n_iterations = 1000\n",
    "learning_rate = 0.1\n",
    "theta_history = gradient_descent(initial_theta, X_b, y, learning_rate, n_iterations)\n",
    "\n",
    "# Function to plot data and current fit based on iteration\n",
    "def plot_gradient_descent_fit(iteration=0):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot data\n",
    "    plt.scatter(X, y, color=\"blue\", label=\"Data\", alpha=0.6)\n",
    "    \n",
    "    # Get current theta (parameters) based on iteration\n",
    "    theta_current = theta_history[iteration]\n",
    "    \n",
    "    # Plot the linear fit for current theta\n",
    "    X_fit = np.array([[0], [2]])  # X values for the line\n",
    "    X_fit_b = np.c_[np.ones((2, 1)), X_fit]  # Add bias term to each instance in X_fit\n",
    "    y_fit = X_fit_b.dot(theta_current)\n",
    "    plt.plot(X_fit, y_fit, color=\"red\", label=f\"Fit at iteration {iteration}\")\n",
    "    \n",
    "    plt.title(f\"Gradient Descent Iteration {iteration}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 15)\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widgets to adjust the number of iterations\n",
    "interact(plot_gradient_descent_fit, \n",
    "         iteration=IntSlider(min=0, max=n_iterations-1, step=1, value=0, description='Iteration'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90adad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
