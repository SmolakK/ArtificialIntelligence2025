{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162f64b1",
   "metadata": {},
   "source": [
    "# Lecture 6: Advanced regression in Python and Ethics in Machine Learning\n",
    "\n",
    "# Advanced regression: Practical approach in Python\n",
    "\n",
    "First, let's start with practical approach to doing advanced regression in Python.\n",
    "\n",
    "First, we will start with a Polynomial Regression method:\n",
    "\n",
    "## Polynomial regression\n",
    "\n",
    "*What It Is*: Polynomial regression extends linear regression by adding combinations of the original features. For example, instead of just fitting a line, it might fit a curve by adding squared terms (e.g., X2) or even higher powers.\n",
    "\n",
    "*How It Works*: In polynomial regression, we create new “features” by raising the original feature values to higher powers. These new features allow the model to bend and fit data that follows a non-linear trend.\n",
    "\n",
    "*Example*: Imagine predicting the height of a plant over time. Initially, growth might be slow, then accelerate, and eventually level off. Linear regression might not fit this data well, but polynomial regression can create a curve that better matches the plant’s growth pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f97926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.309\n",
      "R² Score: 0.285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x214762a6eb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic data with a non-linear relationship\n",
    "np.random.seed(42)\n",
    "X = np.sort(np.random.rand(50, 1) * 1, axis=0)  # Feature values between 0 and 10\n",
    "y = np.sin(5.3 * X.squeeze() + 1.95 * X.squeeze() ** 2) + np.random.normal(0, 0.04, X.shape[0])  # Quadratic relationship with noise\n",
    "\n",
    "\n",
    "# Polynomial transformation\n",
    "degree = 1  # Degree of the polynomial (e.g., quadratic)\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "# Fit linear regression on the transformed polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n",
    "\n",
    "# Visualize the polynomial regression fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='blue', label=\"Data points\")\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label=f\"Polynomial Regression (Degree {degree})\")\n",
    "plt.title(f\"Polynomial Regression Fit (Degree {degree})\")\n",
    "plt.xlabel(\"Feature (X)\")\n",
    "plt.ylabel(\"Target (y)\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c393a4d",
   "metadata": {},
   "source": [
    "So, let's code this in practice, from the scratch.\n",
    "\n",
    "First, let's see our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff5df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.sort(np.random.rand(50, 1) * 1, axis=0)  # Feature values between 0 and 10\n",
    "y = np.sin(5.3 * X.squeeze() + 1.95 * X.squeeze() ** 2) + np.random.normal(0, 0.04, X.shape[0])  # Quadratic relationship with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9c8fe",
   "metadata": {},
   "source": [
    "Let's plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85effad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5168b370",
   "metadata": {},
   "source": [
    "There is a trick to get PolynomialRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd040b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad5f721",
   "metadata": {},
   "source": [
    "After that, we proceed as we would like proceed with a standard Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6275a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdafb1fa",
   "metadata": {},
   "source": [
    "## Advanced models\n",
    "\n",
    "Let's now get familiar with some advanced regression models.\n",
    "\n",
    "We'll do a little experiment, applying these models on the California Housing dataset and trying to find the best algorithm to do that task for us.\n",
    "\n",
    "First, let's apply Polynomial Regression to this dataset.\n",
    "\n",
    "We got our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ac0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas\n",
    "import numpy as np # numpy\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df['MedHouseVal'] = california.target  # Target variable (median house value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0de0a2",
   "metadata": {},
   "source": [
    "Now, let's implement the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d0700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2351a954",
   "metadata": {},
   "source": [
    "## Okay, now let's go with advanced models!\n",
    "\n",
    "### Support Vector Regression (SVR)\n",
    "\n",
    "Support Vector Regression (SVR) is an algorithm based on the principles of Support Vector Machines (SVM), used for regression. The goal of SVR is to find a line, curve, or surface that best maps the relationship between the input and output variables. Here are the key aspects of how SVR works:\n",
    "\n",
    "Support vectors refer to the use of the \"most important\" points to fit the model.\n",
    "\n",
    "#### Epsilon-Tube Principle\n",
    "\n",
    "SVR does not try to exactly fit the model to every data point. Instead, it defines a certain margin of error, called epsilon (ε), within which the model tolerates differences between the predicted and actual values.\n",
    "\n",
    "    If a data point lies within this margin, it is considered \"well fitted\" and does not affect the final solution.\n",
    "    Points outside the margin (lying outside the epsilon-tube) contribute to the error and are penalized in the cost function.\n",
    "\n",
    "#### Optimization and Margins\n",
    "\n",
    "The goal of SVR is to find a line/curve/surface that:\n",
    "\n",
    "    Minimizes deviation from the data while allowing for ε tolerance.\n",
    "    Maximizes the flatness of the function, which means regularization.\n",
    "\n",
    "The optimization formula in SVR takes into account two aspects:\n",
    "\n",
    "    Minimizing ||w||² (restricting the model to be simple).\n",
    "    Minimizing errors for points outside the epsilon-tube (difficult-to-predict points are penalized proportionally to their distance from the margin).\n",
    "\n",
    "#### Penalty for Deviations - Parameter C\n",
    "\n",
    "The parameter C controls the trade-off between fitting the model to the data and its overall complexity:\n",
    "\n",
    "    Low C: The model is more flexible, allowing for larger errors, which may result in underfitting.\n",
    "    High C: The model tries harder to fit the training data, which may lead to overfitting.\n",
    "\n",
    "#### Kernel and Feature Space\n",
    "\n",
    "SVR can work with nonlinear data thanks to the so-called kernel tricks:\n",
    "\n",
    "    A kernel transforms the data into a higher-dimensional space where a linear hyperplane (e.g., a regression line) can be more easily found.\n",
    "\n",
    "#### Popular kernels include:\n",
    "\n",
    "    Linear (simple linear regression)\n",
    "    Polynomial (polynomial model)\n",
    "    RBF (nonlinear model with a radial basis function, suitable for complex data)\n",
    "\n",
    "#### Epsilon and Cost Function\n",
    "\n",
    "The parameter ε (epsilon) defines the width of the tolerance margin:\n",
    "\n",
    "    Smaller epsilon: The model strives to fit the data more closely, which may result in overfitting.\n",
    "    Larger epsilon: The model is more tolerant of errors and ignores minor deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a44641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef09abc675c4e0097b449c6e8b87ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='C', min=0.1), FloatSlider(value=0.1, description='ep…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_svr(C=1.0, epsilon=0.1, kernel='rbf')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(50, 1), axis=0)\n",
    "y = X.ravel() + 4 * (0.5 - np.random.rand(50))\n",
    "\n",
    "# Function to plot SVR with interactive controls\n",
    "def plot_svr(C=1.0, epsilon=0.1, kernel='rbf'):\n",
    "    # Train SVR model\n",
    "    svr = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "    svr.fit(X, y)\n",
    "    \n",
    "    # Generate predictions\n",
    "    X_fit = np.linspace(0, 5, 500).reshape(-1, 1)\n",
    "    y_fit = svr.predict(X_fit)\n",
    "    \n",
    "    # Plot data and SVR predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, color='red', label='Data points')\n",
    "    plt.plot(X_fit, y_fit, color='blue', label='SVR prediction')\n",
    "    plt.fill_between(\n",
    "        X_fit.ravel(),\n",
    "        y_fit - epsilon,\n",
    "        y_fit + epsilon,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label=f\"Epsilon-tube (ε={epsilon})\"\n",
    "    )\n",
    "    plt.title(f\"Support Vector Regression (Kernel: {kernel}, C={C}, ε={epsilon})\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widget\n",
    "interact(\n",
    "    plot_svr,\n",
    "    C=(0.1, 100.0, 0.1),\n",
    "    epsilon=(0.01, 1.0, 0.01),\n",
    "    kernel=['linear', 'poly', 'rbf']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41b8fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace9c532c99f4d8bb1f90b25126b2c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='C', max=10000.0, min=0.1), FloatSlider(value=0.1, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_svr(C=1.0, epsilon=0.1, kernel='rbf')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.sort(5 * np.random.rand(50, 1), axis=0)\n",
    "y = np.sin(X).ravel() + 0.3 * (0.5 - np.random.rand(50))\n",
    "\n",
    "# Function to plot SVR with interactive controls\n",
    "def plot_svr(C=1.0, epsilon=0.1, kernel='rbf'):\n",
    "    # Train SVR model\n",
    "    svr = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "    svr.fit(X, y)\n",
    "    \n",
    "    # Generate predictions\n",
    "    X_fit = np.linspace(0, 5, 500).reshape(-1, 1)\n",
    "    y_fit = svr.predict(X_fit)\n",
    "    \n",
    "    # Plot data and SVR predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, color='red', label='Data points')\n",
    "    plt.plot(X_fit, y_fit, color='blue', label='SVR prediction')\n",
    "    plt.fill_between(\n",
    "        X_fit.ravel(),\n",
    "        y_fit - epsilon,\n",
    "        y_fit + epsilon,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label=f\"Epsilon-tube (ε={epsilon})\"\n",
    "    )\n",
    "    plt.title(f\"Support Vector Regression (Kernel: {kernel}, C={C}, ε={epsilon})\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widget\n",
    "interact(\n",
    "    plot_svr,\n",
    "    C=(0.1, 10000.0, 0.1),\n",
    "    epsilon=(0.01, 10.0, 0.01),\n",
    "    kernel=['linear', 'poly', 'rbf']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28144ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90ab962",
   "metadata": {},
   "source": [
    "# **k-Nearest Neighbors Regression (k-NN Regression)**\n",
    "\n",
    "k-Nearest Neighbors Regression (k-NN Regression) is a simple yet powerful machine learning algorithm that uses distances between data points to predict continuous values. It is a non-parametric method, meaning it does not assume a specific form of the relationship between features and target values.\n",
    "\n",
    "---\n",
    "\n",
    "## **How Does k-NN Work in Regression?**\n",
    "\n",
    "1. **Training Data Collection**:\n",
    "   - The algorithm memorizes all the training data and does not build any preliminary model.\n",
    "\n",
    "2. **For a New Sample (Test Point)**:\n",
    "   - **Step 1**: Compute the distances between the new sample and all points in the training set.\n",
    "     - Commonly used distance metrics are:\n",
    "       - **Euclidean Distance**:\n",
    "         $$\n",
    "         d(x, x') = \\sqrt{\\sum_{i=1}^n (x_i - x'_i)^2}\n",
    "         $$\n",
    "       - **Manhattan Distance**:\n",
    "         $$\n",
    "         d(x, x') = \\sum_{i=1}^n |x_i - x'_i|\n",
    "         $$\n",
    "   - **Step 2**: Select the \\( k \\) nearest neighbors (smallest distances) to the test point.\n",
    "\n",
    "3. **Predicting the Target Value**:\n",
    "   - The predicted value for the test point is the **mean target value \\( y \\)** of the nearest neighbors:\n",
    "     $$\n",
    "     \\hat{y} = \\frac{1}{k} \\sum_{i=1}^k y_i\n",
    "     $$\n",
    "   - Weighted averages can also be used, where closer neighbors have a larger influence on the result:\n",
    "     $$\n",
    "     \\hat{y} = \\frac{\\sum_{i=1}^k w_i \\cdot y_i}{\\sum_{i=1}^k w_i}\n",
    "     $$\n",
    "     where \\( w_i \\) is the inverse of the distance to the neighbor \\( w_i = \\frac{1}{d(x, x'_i) + \\epsilon} \\), and \\( \\epsilon \\) is a small value to avoid division by zero.\n",
    "\n",
    "4. **Repeat for All Test Points**:\n",
    "   - The algorithm performs the above steps for each sample in the test set.\n",
    "\n",
    "---\n",
    "\n",
    "## **k-NN Hyperparameters**\n",
    "\n",
    "1. **Number of Neighbors \\( k \\)**:\n",
    "   - **Small \\( k \\)**:\n",
    "     - The model is more sensitive to noise in the data (prone to overfitting).\n",
    "   - **Large \\( k \\)**:\n",
    "     - The model averages values over a broader range, which may lead to underfitting.\n",
    "\n",
    "2. **Distance Metric**:\n",
    "   - The most commonly used metric is Euclidean distance, but others like Manhattan, Minkowski, or specialized metrics can be applied.\n",
    "\n",
    "3. **Neighbor Weights**:\n",
    "   - By default, all neighbors have equal weights.\n",
    "   - Distance-based weights can be used so that closer neighbors have a greater influence.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages of k-NN Regression**\n",
    "\n",
    "1. **Simplicity**:\n",
    "   - The algorithm is easy to understand and implement.\n",
    "\n",
    "2. **Flexibility**:\n",
    "   - Works well with data having complex and non-linear relationships.\n",
    "\n",
    "3. **No Assumptions**:\n",
    "   - Does not require any prior assumptions about the data distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **Disadvantages of k-NN Regression**\n",
    "\n",
    "1. **Computational Cost**:\n",
    "   - The algorithm requires distance computations for all points in the training set for each test sample, which can be expensive for large datasets.\n",
    "\n",
    "2. **Sensitivity to Data**:\n",
    "   - Sensitive to noise and outliers, especially for small \\( k \\).\n",
    "\n",
    "3. **Scaling Issues**:\n",
    "   - The algorithm is sensitive to differences in the scale of features, so standardization or normalization of data is usually necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0550eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f20b4b7fb9d4d4682e741f66acc1779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='k (Neighbors)', max=20, min=1), RadioButtons(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_knn(n_neighbors=3, weights='uniform')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "X_train, X_test = X[:160], X[160:]\n",
    "y_train, y_test = y[:160], y[160:]\n",
    "\n",
    "# Interactive function for k-NN\n",
    "def interactive_knn(n_neighbors=3, weights='uniform'):\n",
    "    # Train k-NN regressor\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, p=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Plot training data, test data, and predictions\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Scatter plot of training and test data\n",
    "    plt.scatter(X_train, y_train, label=\"Training Data\", color='blue', alpha=0.7)\n",
    "    plt.scatter(X_test, y_test, label=\"Test Data\", color='orange', alpha=0.7)\n",
    "    \n",
    "    # Line plot of predictions\n",
    "    X_range = np.linspace(X.min(), X.max(), 500).reshape(-1, 1)\n",
    "    y_pred_range = knn.predict(X_range)\n",
    "    plt.plot(X_range, y_pred_range, color='red', label=\"k-NN Predictions\", linewidth=2)\n",
    "    \n",
    "    # Titles and labels\n",
    "    plt.title(f\"k-NN Regression (k={n_neighbors}, weights='{weights}')\\nMSE: {mse:.2f}\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Target\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets for k and weights\n",
    "interact(\n",
    "    interactive_knn,\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=20, step=1, value=3, description='k (Neighbors)'),\n",
    "    weights=widgets.RadioButtons(\n",
    "        options=['uniform', 'distance'],\n",
    "        value='uniform',\n",
    "        description='Weights:'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a472a",
   "metadata": {},
   "source": [
    "# **Decision Trees**\n",
    "\n",
    "Decision trees are a popular machine learning algorithm that can be used for both classification and regression tasks. For regression, decision trees are employed to predict continuous values, making them a powerful tool for modeling data with nonlinear and complex relationships.\n",
    "\n",
    "---\n",
    "\n",
    "## **Structure of a Decision Tree**\n",
    "\n",
    "A decision tree is a diagram-like structure where data is split based on logical conditions, forming nodes and branches.\n",
    "\n",
    "- **Root Node**: The starting point, containing all input data.\n",
    "- **Decision Nodes**: Points where the data is split based on a specific condition (e.g., the feature that best explains the data at that point).\n",
    "- **Leaves**: Terminal nodes representing the predicted value in the case of regression.\n",
    "\n",
    "---\n",
    "\n",
    "## **Regression Using Decision Trees**\n",
    "\n",
    "### Data Splitting - The Learning Process\n",
    "\n",
    "The tree iteratively splits the input data into subsets based on a chosen feature and condition that minimizes prediction error.\n",
    "\n",
    "- For example: \"Apartment area > 50m² → yes or no\" divides the data into two subsets, each with a specific predicted value.\n",
    "\n",
    "Metrics such as Mean Squared Error (MSE) or Mean Absolute Error (MAE) are used to determine the best split.\n",
    "\n",
    "- **Splitting Criterion**: The difference between the actual value and the mean value in the resulting subgroup.\n",
    "\n",
    "The algorithm continues splitting until it reaches a stopping criterion, such as:\n",
    "\n",
    "- Minimum number of samples in a leaf,\n",
    "- Maximum depth of the tree,\n",
    "- No further improvement in error.\n",
    "\n",
    "---\n",
    "\n",
    "### Prediction\n",
    "\n",
    "The predicted value at a leaf node is the mean of the target values in that data subset.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages**\n",
    "\n",
    "- Trees are very simple to use and intuitive.\n",
    "- They handle highly nonlinear relationships effectively.\n",
    "- No need for data scaling.\n",
    "\n",
    "---\n",
    "\n",
    "## **Disadvantages**\n",
    "\n",
    "- Trees are prone to overfitting.\n",
    "- Predictions are averages, leading to step-like outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## **When to Use Decision Trees**\n",
    "\n",
    "- When the data is highly nonlinear.\n",
    "- When model interpretability is crucial.\n",
    "- When there are complex interactions between features that are difficult to model with methods like polynomial regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d61c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a08415d3bd48cca2efb6ef03ae6a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='Max Depth', max=10, min=1), IntSlider(value=2, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_tree_with_plot(max_depth=3, min_samples_split=2, min_samples_leaf=1)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import additional library for tree visualization\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Adjust interactive function to include tree visualization\n",
    "def interactive_tree_with_plot(max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "    # Train the Decision Tree Regressor with selected hyperparameters\n",
    "    regressor = DecisionTreeRegressor(\n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and test set\n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    y_pred_test = regressor.predict(X_test)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Create subplots for predictions and tree structure\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Plot the data and the regression tree predictions\n",
    "    X_range = np.linspace(X.min(), X.max(), 500).reshape(-1, 1)\n",
    "    y_pred_range = regressor.predict(X_range)\n",
    "    \n",
    "    axs[0].scatter(X_train, y_train, color='blue', label='Training Data', alpha=0.6)\n",
    "    axs[0].scatter(X_test, y_test, color='orange', label='Test Data', alpha=0.6)\n",
    "    axs[0].plot(X_range, y_pred_range, color='red', label='Tree Prediction', linewidth=2)\n",
    "    axs[0].set_title(f\"Decision Tree Regressor\\nTrain MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "    axs[0].set_xlabel(\"Feature\")\n",
    "    axs[0].set_ylabel(\"Target\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Visualize the decision tree structure\n",
    "    plot_tree(regressor, filled=True, feature_names=[\"Feature\"], ax=axs[1])\n",
    "    axs[1].set_title(\"Decision Tree Structure\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets for hyperparameters\n",
    "interact(\n",
    "    interactive_tree_with_plot,\n",
    "    max_depth=widgets.IntSlider(min=1, max=10, step=1, value=3, description='Max Depth'),\n",
    "    min_samples_split=widgets.IntSlider(min=2, max=20, step=1, value=2, description='Min Samples Split'),\n",
    "    min_samples_leaf=widgets.IntSlider(min=1, max=10, step=1, value=1, description='Min Samples Leaf')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268fec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0266ff5b19a04664bb088f4b39690154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='Max Depth', max=10, min=1), IntSlider(value=2, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_tree_with_plot_nonlinear(max_depth=3, min_samples_split=2, min_samples_leaf=1)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a more non-linear dataset\n",
    "np.random.seed(42)\n",
    "X_nl = np.sort(np.random.rand(200, 1) * 10, axis=0)  # Random values between 0 and 10\n",
    "y_nl = np.sin(X_nl).ravel() + np.random.normal(0, 0.2, X_nl.shape[0])  # Sinusoidal with noise\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_nl, X_test_nl, y_train_nl, y_test_nl = train_test_split(X_nl, y_nl, test_size=0.2, random_state=42)\n",
    "\n",
    "# Interactive function for non-linear example\n",
    "def interactive_tree_with_plot_nonlinear(max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "    # Train the Decision Tree Regressor with selected hyperparameters\n",
    "    regressor = DecisionTreeRegressor(\n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    regressor.fit(X_train_nl, y_train_nl)\n",
    "    \n",
    "    # Predict on the training and test set\n",
    "    y_pred_train_nl = regressor.predict(X_train_nl)\n",
    "    y_pred_test_nl = regressor.predict(X_test_nl)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    train_mse = mean_squared_error(y_train_nl, y_pred_train_nl)\n",
    "    test_mse = mean_squared_error(y_test_nl, y_pred_test_nl)\n",
    "    \n",
    "    # Create subplots for predictions and tree structure\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(18, 16))\n",
    "    \n",
    "    # Plot the data and the regression tree predictions\n",
    "    X_range = np.linspace(X_nl.min(), X_nl.max(), 500).reshape(-1, 1)\n",
    "    y_pred_range = regressor.predict(X_range)\n",
    "    \n",
    "    axs[0].scatter(X_train_nl, y_train_nl, color='blue', label='Training Data', alpha=0.6)\n",
    "    axs[0].scatter(X_test_nl, y_test_nl, color='orange', label='Test Data', alpha=0.6)\n",
    "    axs[0].plot(X_range, y_pred_range, color='red', label='Tree Prediction', linewidth=2)\n",
    "    axs[0].set_title(f\"Decision Tree Regressor (Non-Linear Example)\\nTrain MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "    axs[0].set_xlabel(\"Feature\")\n",
    "    axs[0].set_ylabel(\"Target\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Visualize the decision tree structure\n",
    "    plot_tree(regressor, filled=True, feature_names=[\"Feature\"], ax=axs[1])\n",
    "    axs[1].set_title(\"Decision Tree Structure\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets for hyperparameters\n",
    "interact(\n",
    "    interactive_tree_with_plot_nonlinear,\n",
    "    max_depth=widgets.IntSlider(min=1, max=10, step=1, value=3, description='Max Depth'),\n",
    "    min_samples_split=widgets.IntSlider(min=2, max=20, step=1, value=2, description='Min Samples Split'),\n",
    "    min_samples_leaf=widgets.IntSlider(min=1, max=10, step=1, value=1, description='Min Samples Leaf')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae00f1",
   "metadata": {},
   "source": [
    "## Let's compare how these models perform on our California Housing dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82b1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
